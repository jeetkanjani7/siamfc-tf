{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect to Track "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One drawback of many correlation trackers [1, 25] is that they only work on\n",
    "single targets and do not account for changes in object scale\n",
    "and aspect ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our approach builds on R-FCN  which is a simple and\n",
    "efficient framework for object detection on region proposals with a fully convolutional nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-FCN reduces the cost for region classification by pushing\n",
    "the region-wise operations to the end of the network with\n",
    "the introduction of a position-sensitive RoI pooling layer\n",
    "which works on convolutional features that encode the spa-\n",
    "tially subsampled class scores of input RoIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At its core, RoIPool shares the forward pass of a CNN for an image across its subregions. Then, the features in each region are pooled (usually using max pooling). So all it takes us is one pass of the original image as opposed to ~2000!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional feature maps used by region-based detectors, like Fast R- CNN, can also be used for generating region proposals [thus enabling nearly cost-free region proposals]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faster R-CNN generates these region proposals from CNN features. Faster R-CNN adds a Fully Convolutional Network on top of the features of the CNN creating what’s known as the Region Proposal Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layer takes two inputs:\n",
    "\n",
    "   1) A fixed-size feature map obtained from a deep convolutional network with several convolutions and max pooling layers.\n",
    "   \n",
    "   2) An N x 5 matrix of representing a list of regions of interest, where N is a number of RoIs. The first column represents the image index and the remaining four are the coordinates of the top left and bottom right corners of the region.\n",
    "\n",
    "\n",
    "For every region of interest from the input list, it takes a section of the input feature map that corresponds to it and scales it to some pre-defined size (e.g., 7×7). The scaling is done by:\n",
    "\n",
    "   -> Dividing the region proposal into equal-sized sections (the number of which is the same as the dimension of the output)\n",
    "   \n",
    "   -> Finding the largest value in each section\n",
    "   \n",
    "   -> Copying these max values to the output buffer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking is also an extensively studied prob-\n",
    "lem in computer vision with most recent progress devoted\n",
    "to trackers operating on deep ConvNet features. In [26]\n",
    "a ConvNet is fine-tuned at test-time to track a target from\n",
    "the same video via detection and bounding box regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this tracker predicts a bounding box\n",
    "instead of just the position, it is able to model changes in\n",
    "scale and aspect of the tracked template. The major draw-\n",
    "back of this approach is that it only can process a single tar-\n",
    "get template and it also has to rely on significant data aug-\n",
    "mentation to learn all possible transformations of tracked\n",
    "boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
