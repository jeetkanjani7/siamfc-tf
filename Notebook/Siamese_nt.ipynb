{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import sys\n",
    "import os.path\n",
    "import nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/home/jeetkanjani7/Tonbo/siamfc-tf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.convolutional import set_convolutional\n",
    "from src.crops import extract_crops_z, extract_crops_x, pad_frame, resize_images\n",
    "from src.parse_arguments import parse_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_x_ph = tf.placeholder(tf.float64)\n",
    "pos_y_ph = tf.placeholder(tf.float64)\n",
    "z_sz_ph = tf.placeholder(tf.float64)\n",
    "\n",
    "x_sz0_ph = tf.placeholder(tf.float64)\n",
    "x_sz1_ph = tf.placeholder(tf.float64)\n",
    "x_sz2_ph = tf.placeholder(tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_conv_stride = np.array([2,1,1,1,1])\n",
    "_filtergroup_yn = np.array([0,1,0,1,1], dtype=bool)\n",
    "_bnorm_yn = np.array([1,1,1,1,0], dtype=bool)\n",
    "_relu_yn = np.array([1,1,1,1,0], dtype=bool)\n",
    "_pool_stride = np.array([2,1,0,0,0]) # 0 means no pool\n",
    "_pool_sz = 3\n",
    "_bnorm_adjust = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(_conv_stride) == len(_filtergroup_yn) == len(_bnorm_yn) == len(_relu_yn) == len(_pool_stride), ('These arrays of flags should have same length')\n",
    "assert all(_conv_stride) >= True, ('The number of conv layers is assumed to define the depth of the network')\n",
    "_num_layers = len(_conv_stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tracking_graph_nt(final_score_sz, design, env):\n",
    "    filename = tf.placeholder(tf.string, [], name = 'filename')\n",
    "    image_file = tf.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_file)\n",
    "\n",
    "    image = 255.0 * tf.image.convert_image_dtype(image, tf.float32)\n",
    "    frame_sz = tf.shape(image)\n",
    "    if design.pad_with_image_mean:\n",
    "        avg_chan = tf.reduce_mean(image, axis=(0,1), name = 'avg_chan')\n",
    "    else:\n",
    "        avg_chan = None\n",
    "    frame_padded_z, npad_z = pad_frame(image, frame_sz, pos_x_ph,pos_y_ph, z_sz_ph, avg_chan)\n",
    "    frame_padded_z = tf.cast(frame_padded_z, tf.float32)\n",
    "    \n",
    "    z_crops = extract_crops_z(image, npad_z, pos_x_ph, pos_y_ph, z_sz_ph, design.exemplar_sz)\n",
    "    frame_padded_x, npad_x = pad_frame(image, frame_sz, pos_x_ph, pos_y_ph, x_sz2_ph, avg_chan)\n",
    "    frame_padded_x = tf.cast(frame_padded_x, tf.float32)\n",
    "    \n",
    "    x_crops = extract_crops_x(frame_padded_x, npad_x, pos_x_ph, pos_y_ph, x_sz0_ph, x_sz1_ph, x_sz2_ph, 255)#design.search_sz)\n",
    "    template_z, template_x, p_names_list, p_val_list = create_siamese(os.path.join(env.root_pretrained, design.net), x_crops, z_crops)\n",
    "    template_z = tf.squeeze(template_z)\n",
    "    template_z = tf.stack([template_z, template_z, template_z])\n",
    "    \n",
    "    scores = match_templates(template_z, template_x, p_names_list, p_val_list)\n",
    "    score_up = tf.image.resize_images(scores, (final_score_sz, final_score_sz), method=tf.image.ResizeMethod.BICUBIC, align_corners= True)\n",
    "    return filename, image, template_z, score_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_siamese(net_path, net_x, net_z):\n",
    "    print(\"hi\")\n",
    "    params_names_list, params_values_list = import_from_matconvnet(net_path)\n",
    "    print params_names_list\n",
    "    for i in xrange(_num_layers):\n",
    "        print '> Layer '+str(i+1)\n",
    "        # conv\n",
    "        conv_W_name = _find_params('conv'+str(i+1)+'f', params_names_list)[0]\n",
    "        conv_b_name = _find_params('conv'+str(i+1)+'b', params_names_list)[0]\n",
    "        print '\\t\\tCONV: setting '+conv_W_name+' '+conv_b_name\n",
    "        print '\\t\\tCONV: stride '+str(_conv_stride[i])+', filter-group '+str(_filtergroup_yn[i])\n",
    "        conv_W = params_values_list[params_names_list.index(conv_W_name)]\n",
    "        conv_b = params_values_list[params_names_list.index(conv_b_name)]\n",
    "        # batchnorm\n",
    "        if _bnorm_yn[i]:\n",
    "            bn_beta_name = _find_params('bn'+str(i+1)+'b', params_names_list)[0]\n",
    "            bn_gamma_name = _find_params('bn'+str(i+1)+'m', params_names_list)[0]\n",
    "            bn_moments_name = _find_params('bn'+str(i+1)+'x', params_names_list)[0]\n",
    "            print '\\t\\tBNORM: setting '+bn_beta_name+' '+bn_gamma_name+' '+bn_moments_name\n",
    "            bn_beta = params_values_list[params_names_list.index(bn_beta_name)]\n",
    "            bn_gamma = params_values_list[params_names_list.index(bn_gamma_name)]\n",
    "            bn_moments = params_values_list[params_names_list.index(bn_moments_name)]\n",
    "            bn_moving_mean = bn_moments[:,0]\n",
    "            bn_moving_variance = bn_moments[:,1]**2 # saved as std in matconvnet\n",
    "        else:\n",
    "            bn_beta = bn_gamma = bn_moving_mean = bn_moving_variance = []\n",
    "        \n",
    "        # set up conv \"block\" with bnorm and activation \n",
    "        net_x = set_convolutional(net_x, conv_W, np.swapaxes(conv_b,0,1), _conv_stride[i], \\\n",
    "                            bn_beta, bn_gamma, bn_moving_mean, bn_moving_variance, \\\n",
    "                            filtergroup=_filtergroup_yn[i], batchnorm=_bnorm_yn[i], activation=_relu_yn[i], \\\n",
    "                            scope='conv'+str(i+1), reuse=False)\n",
    "        \n",
    "        # notice reuse=True for Siamese parameters sharing\n",
    "        net_z = set_convolutional(net_z, conv_W, np.swapaxes(conv_b,0,1), _conv_stride[i], \\\n",
    "                            bn_beta, bn_gamma, bn_moving_mean, bn_moving_variance, \\\n",
    "                            filtergroup=_filtergroup_yn[i], batchnorm=_bnorm_yn[i], activation=_relu_yn[i], \\\n",
    "                            scope='conv'+str(i+1), reuse=True)    \n",
    "        \n",
    "        # add max pool if required\n",
    "        if _pool_stride[i]>0:\n",
    "            print '\\t\\tMAX-POOL: size '+str(_pool_sz)+ ' and stride '+str(_pool_stride[i])\n",
    "            net_x = tf.nn.max_pool(net_x, [1,_pool_sz,_pool_sz,1], strides=[1,_pool_stride[i],_pool_stride[i],1], padding='VALID', name='pool'+str(i+1))\n",
    "            net_z = tf.nn.max_pool(net_z, [1,_pool_sz,_pool_sz,1], strides=[1,_pool_stride[i],_pool_stride[i],1], padding='VALID', name='pool'+str(i+1))\n",
    "\n",
    "\n",
    "\n",
    "    return net_z, net_x, params_names_list, params_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_from_matconvnet(net_path):\n",
    "    mat = scipy.io.loadmat(net_path)\n",
    "    net_do_mat = mat.get('net')\n",
    "    \n",
    "    params = net_do_mat['params']\n",
    "    params = params[0][0]\n",
    "    params_names = params['name'][0]\n",
    "    params_names_list =  [params_names[p][0] for p in range(params_names.size)]\n",
    "    params_values = params['value'][0]\n",
    "    params_value_list = [params_values[p] for p in range(params_values.size)]\n",
    "    return params_names_list, params_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_templates(net_z, net_x, params_names_list, params_values_list):\n",
    "    # finalize network\n",
    "    # z, x are [B, H, W, C]\n",
    "    net_z = tf.transpose(net_z, perm=[1,2,0,3])\n",
    "    net_x = tf.transpose(net_x, perm=[1,2,0,3])\n",
    "    # z, x are [H, W, B, C]\n",
    "    Hz, Wz, B, C = tf.unstack(tf.shape(net_z))\n",
    "    Hx, Wx, Bx, Cx = tf.unstack(tf.shape(net_x))\n",
    "    # assert B==Bx, ('Z and X should have same Batch size')\n",
    "    # assert C==Cx, ('Z and X should have same Channels number')\n",
    "    net_z = tf.reshape(net_z, (Hz, Wz, B*C, 1))\n",
    "    net_x = tf.reshape(net_x, (1, Hx, Wx, B*C))\n",
    "    net_final = tf.nn.depthwise_conv2d(net_x, net_z, strides=[1,1,1,1], padding='VALID')\n",
    "    # final is [1, Hf, Wf, BC]\n",
    "    net_final = tf.concat(tf.split(net_final, 3, axis=3), axis=0)\n",
    "    # final is [B, Hf, Wf, C]\n",
    "    net_final = tf.expand_dims(tf.reduce_sum(net_final, axis=3), axis=3)\n",
    "    # final is [B, Hf, Wf, 1]\n",
    "    if _bnorm_adjust:\n",
    "        bn_beta = params_values_list[params_names_list.index('fin_adjust_bnb')]\n",
    "        bn_gamma = params_values_list[params_names_list.index('fin_adjust_bnm')]\n",
    "        bn_moments = params_values_list[params_names_list.index('fin_adjust_bnx')]\n",
    "        bn_moving_mean = bn_moments[:,0]\n",
    "        bn_moving_variance = bn_moments[:,1]**2\n",
    "        net_final = tf.layers.batch_normalization(net_final, beta_initializer=tf.constant_initializer(bn_beta),\n",
    "                                                gamma_initializer=tf.constant_initializer(bn_gamma),\n",
    "                                                moving_mean_initializer=tf.constant_initializer(bn_moving_mean),\n",
    "                                                moving_variance_initializer=tf.constant_initializer(bn_moving_variance),\n",
    "                                                training=False, trainable=False)\n",
    "\n",
    "    return net_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_params(x, params):\n",
    "    matching = [s for s in params if x in s]\n",
    "    assert len(matching)==1, ('Ambiguous param name found')    \n",
    "    return matching\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
